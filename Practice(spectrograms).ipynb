{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice(spectrograms).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ufuff/colab-ipynb/blob/main/Practice(spectrograms).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNmaZ7IonBou"
      },
      "source": [
        "данные сбалансированы, класс с шумом отсутствует"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNzc-zVvSasQ"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX6K0HRWwl31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6388b686-824a-47a2-99b9-0ffe34ec2bd7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-_ozAww6x0"
      },
      "source": [
        "import scipy.io.wavfile as wav\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy.fft\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree, metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "from __future__ import division, print_function\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import os\n",
        "from time import time\n",
        "from os.path import isfile, join\n",
        "%matplotlib inline \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7zTcYhaw9jr"
      },
      "source": [
        "!mkdir /spectrograms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kjzh05uxBuP"
      },
      "source": [
        "def wav_to_spectrogram(audio_path, save_path, spectrogram_dimensions=(64, 64), noverlap=16, cmap='gray_r'):\n",
        "    sample_rate, samples = wav.read(audio_path)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches((spectrogram_dimensions[0]/fig.get_dpi(), spectrogram_dimensions[1]/fig.get_dpi()))\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax.specgram(samples, cmap=cmap, Fs=2, noverlap=noverlap)\n",
        "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
        "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
        "    fig.savefig(save_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "\n",
        "\n",
        "def dir_to_spectrogram(audio_dir, spectrogram_dir, spectrogram_dimensions=(64, 64), noverlap=16, cmap='gray_r'):\n",
        "    file_names = [f for f in listdir(audio_dir) if isfile(join(audio_dir, f)) and '.wav' in f]\n",
        "\n",
        "    for file_name in file_names:\n",
        "        print(file_name)\n",
        "        audio_path = audio_dir + file_name\n",
        "        spectogram_path = spectrogram_dir + file_name.replace('.wav', '.png')\n",
        "        wav_to_spectrogram(audio_path, spectogram_path, spectrogram_dimensions=spectrogram_dimensions, noverlap=noverlap, cmap=cmap)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    audio_dir = \"/content/drive/My Drive/recordings/\"\n",
        "    spectrogram_dir = \"/spectrograms/\"\n",
        "    dir_to_spectrogram(audio_dir, spectrogram_dir)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9IRHNfxxVAt"
      },
      "source": [
        "def get_arr(file):\n",
        "  img = color.rgb2gray(io.imread(file))\n",
        "  arr = np.array(img)\n",
        "  arr = arr / 255\n",
        "  return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV7u-GGHxbtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0f41b7bc-741e-45ec-f7df-f9a2955121be"
      },
      "source": [
        "y_data = np.array([])\n",
        "x_data = np.array([])\n",
        "\n",
        "y_train = np.array([])\n",
        "x_train = np.array([])\n",
        "y_test = np.array([])\n",
        "x_test = np.array([])\n",
        "\n",
        "indir = '/spectrograms/'\n",
        "for root, dirs, filenames in os.walk(indir):\n",
        "    for f in filenames:\n",
        "        y_data = np.append(y_data, f[0]) \n",
        "        \n",
        "x_data = np.array([get_arr(indir+f) for f in filenames])\n",
        "\n",
        "y_train = y_data[:1800]\n",
        "x_train = x_data[:1800]\n",
        "y_test = y_data[1800:]\n",
        "x_test = x_data[1800:]\n",
        "\n",
        "print(len(x_train))\n",
        "print(y_train.size)\n",
        "print(len(x_test))\n",
        "print(y_test.size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1800\n",
            "1800\n",
            "200\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7DxuI4-CWci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a15934b-51ef-4cb2-8333-e82353458094"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '0', '7', '4', '9', '9', '6', '9', '0', '2'], dtype='<U32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at37PlAE0GI6"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 4096)\n",
        "x_test = x_test.reshape(x_test.shape[0], 4096)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_mwJk6t8-QU"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWeJRiE9zSjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a068bd14-95b6-4e4e-8bbf-9cad00a365d5"
      },
      "source": [
        "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(x_train, y_train)\n",
        "clf.score(x_train, y_train)\n",
        "predictions = clf.predict(x_test)\n",
        "metrics.accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kozyXK7Y9DcH"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7LNnfM79UU3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6919478-5a6b-4729-db55-e0e22f58bcd4"
      },
      "source": [
        "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=10, min_samples_leaf = 3)\n",
        "decision_tree = decision_tree.fit(x_train, y_train)\n",
        "predictions = decision_tree.predict(x_test)\n",
        "metrics.accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvphlHGF9vvD"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-5PI_Gt9tg-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d01516-7bcb-4f55-9bda-a58b59d0679b"
      },
      "source": [
        "random_forest = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1)\n",
        "random_forest.fit(x_train,y_train)\n",
        "predictions = random_forest.predict(x_test)\n",
        "metrics.accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE0bLfM893lM"
      },
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8m2cUU096kB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "22b89a29-b9ad-4ce9-bc09-a521aac98ae5"
      },
      "source": [
        "g_boosting = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 5, n_estimators = 150, min_child_weight = 3)\n",
        "g_boosting.fit(x_train,y_train)\n",
        "print(g_boosting.score(x_train, y_train))\n",
        "print(g_boosting.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECKkJ82-B1h"
      },
      "source": [
        "### Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-vel1ZyAfiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e31064c0-e09b-40f5-a4aa-d1620e937a31"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten \n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4JcR8kj-Dl_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dd84b6a7-7c9b-46d1-ad75-769836bc25a5"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 64, 64, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 64, 64, 1)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1800, 64, 64, 1)\n",
            "(200, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrqjsNAW-bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5f0f0dc2-391b-47df-c3c5-19b424fd7557"
      },
      "source": [
        "y_train = utils.to_categorical(y_train)\n",
        "print(y_train[:5])\n",
        "y_test = utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jz9KeW3-jLS"
      },
      "source": [
        "random_seed = 2\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfZfIHhb-nxA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c58ba677-3372-4eec-8e84-40734b8af6da"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (64,64,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE3b7X_C-rj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "eaa964fa-b89a-4cfa-c5d8-50e288ca82c0"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 32)        25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               4194560   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 4,279,018\n",
            "Trainable params: 4,279,018\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmuH1LV-uNV"
      },
      "source": [
        "сheckpoint = ModelCheckpoint('recognizer', \n",
        "                              monitor='val_acc', \n",
        "                              save_best_only=True,\n",
        "                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1rhtMYS-wKl"
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W_xFelx-yJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a71851b-fd68-4367-d9ae-2fa98a4b011d"
      },
      "source": [
        "batch_size=96\n",
        "history = model.fit(X_train,Y_train, batch_size=batch_size, \n",
        "                    epochs=15,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                    verbose=1,\n",
        "                    callbacks=[сheckpoint, learning_rate_reduction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "Train on 16 samples, validate on 180 samples\n",
            "Epoch 1/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 2.2960 - acc: 0.1234\n",
            "Epoch 00001: val_acc improved from -inf to 0.42222, saving model to recognizer\n",
            "16/16 [==============================] - 27s 2s/step - loss: 2.2932 - acc: 0.1280 - val_loss: 2.2316 - val_acc: 0.4222\n",
            "Epoch 2/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 1.7182 - acc: 0.4418\n",
            "Epoch 00002: val_acc improved from 0.42222 to 0.77222, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 1.6800 - acc: 0.4522 - val_loss: 0.8328 - val_acc: 0.7722\n",
            "Epoch 3/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.7395 - acc: 0.7410\n",
            "Epoch 00003: val_acc improved from 0.77222 to 0.88889, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.7261 - acc: 0.7457 - val_loss: 0.3419 - val_acc: 0.8889\n",
            "Epoch 4/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.4276 - acc: 0.8505\n",
            "Epoch 00004: val_acc improved from 0.88889 to 0.92222, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.4216 - acc: 0.8520 - val_loss: 0.2304 - val_acc: 0.9222\n",
            "Epoch 5/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.2962 - acc: 0.8935\n",
            "Epoch 00005: val_acc improved from 0.92222 to 0.93889, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.2934 - acc: 0.8945 - val_loss: 0.1685 - val_acc: 0.9389\n",
            "Epoch 6/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.2195 - acc: 0.9212\n",
            "Epoch 00006: val_acc did not improve from 0.93889\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.2186 - acc: 0.9218 - val_loss: 0.1425 - val_acc: 0.9333\n",
            "Epoch 7/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.1659 - acc: 0.9404\n",
            "Epoch 00007: val_acc improved from 0.93889 to 0.95000, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.1653 - acc: 0.9404 - val_loss: 0.1360 - val_acc: 0.9500\n",
            "Epoch 8/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.1429 - acc: 0.9497\n",
            "Epoch 00008: val_acc did not improve from 0.95000\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.1418 - acc: 0.9502 - val_loss: 0.1299 - val_acc: 0.9333\n",
            "Epoch 9/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.1141 - acc: 0.9594\n",
            "Epoch 00009: val_acc did not improve from 0.95000\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.1132 - acc: 0.9596 - val_loss: 0.1177 - val_acc: 0.9333\n",
            "Epoch 10/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.0978 - acc: 0.9647\n",
            "Epoch 00010: val_acc did not improve from 0.95000\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0967 - acc: 0.9654 - val_loss: 0.1139 - val_acc: 0.9500\n",
            "Epoch 11/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.0742 - acc: 0.9740\n",
            "Epoch 00011: val_acc improved from 0.95000 to 0.96667, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0736 - acc: 0.9743 - val_loss: 0.0912 - val_acc: 0.9667\n",
            "Epoch 12/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.0618 - acc: 0.9776\n",
            "Epoch 00012: val_acc improved from 0.96667 to 0.97222, saving model to recognizer\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0625 - acc: 0.9772 - val_loss: 0.0990 - val_acc: 0.9722\n",
            "Epoch 13/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.0603 - acc: 0.9787\n",
            "Epoch 00013: val_acc did not improve from 0.97222\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0603 - acc: 0.9790 - val_loss: 0.1025 - val_acc: 0.9611\n",
            "Epoch 14/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.0543 - acc: 0.9802\n",
            "Epoch 00014: val_acc did not improve from 0.97222\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0539 - acc: 0.9802 - val_loss: 0.1005 - val_acc: 0.9556\n",
            "Epoch 15/15\n",
            "15/16 [===========================>..] - ETA: 1s - loss: 0.0541 - acc: 0.9807\n",
            "Epoch 00015: val_acc did not improve from 0.97222\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0540 - acc: 0.9809 - val_loss: 0.0866 - val_acc: 0.9611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKNmW8JT-__l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00aaaa6a-bb21-49d4-f08d-e8bf03da7f9e"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 1ms/sample - loss: 0.0828 - acc: 0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}